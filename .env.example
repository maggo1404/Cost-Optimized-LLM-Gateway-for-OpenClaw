# ============================================
# LLM Gateway v2.0 - Environment
# ============================================

# ----- Server (PFLICHT) -----
GATEWAY_SECRET=dein-geheimer-schluessel

# ----- Lokales LLM (llama.cpp) -----
LOCAL_LLM_ENABLED=true
# llama.cpp Server URL
LOCAL_LLM_URL=http://host.docker.internal:8080/v1
LOCAL_LLM_API_KEY=local

# Empfohlene Modelle für Drei-Tier-Routing:
# Router/Classifier (schnell): GLM-4.7-Flash-UD-Q5_K_XL
# LOCAL Tier (einfach): Llama-3.2-3B-Instruct-UD-Q4_K_XL  
# CHEAP Tier (mittel): qwen2.5-14b-instruct-q6_k
# Embeddings: nomic-embed-text-v1.5.Q8_0
LOCAL_LLM_MODEL=GLM-4.7-Flash-UD-Q5_K_XL

# Zusätzliche Modelle für Cheap-Tier
LOCAL_LLM_MODEL_CHEAP=qwen2.5-14b-instruct-q6_k

# ----- Anthropic (PREMIUM Tier) -----
ANTHROPIC_API_KEY=
ANTHROPIC_SETUP_TOKEN=

# ----- Routing -----
ROUTER_PROVIDER=local

# ----- Budget (USD) -----
DAILY_BUDGET_SOFT=5.0
DAILY_BUDGET_MEDIUM=15.0
DAILY_BUDGET_HARD=50.0

# ----- Ports -----
GATEWAY_PORT=8000
DASHBOARD_PORT=3000
