# ============================================
# LLM Gateway v2.0 - Docker Compose
# ============================================
# 
# Schnellstart:
#   1. cp config/config.yaml.example config/config.yaml
#   2. Konfiguration anpassen
#   3. docker-compose up -d
#
# Mit Dashboard:
#   docker-compose --profile dashboard up -d
#
# Mit Monitoring (Prometheus/Grafana):
#   docker-compose --profile monitoring up -d

version: "3.8"

services:
  # ==========================================
  # LLM Gateway (Hauptservice)
  # ==========================================
  gateway:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: llm-gateway
    restart: unless-stopped
    ports:
      - "${GATEWAY_PORT:-8000}:8000"
    
    environment:
      # ----- Server -----
      - GATEWAY_SECRET=${GATEWAY_SECRET:?Setze GATEWAY_SECRET in .env}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      
      # ----- Lokales LLM (Ollama, LM Studio, etc.) -----
      - LOCAL_LLM_ENABLED=${LOCAL_LLM_ENABLED:-true}
      # Für Docker: host.docker.internal, für Linux: 172.17.0.1
      - LOCAL_LLM_URL=${LOCAL_LLM_URL:-http://host.docker.internal:11434/v1}
      - LOCAL_LLM_API_KEY=${LOCAL_LLM_API_KEY:-local}
      - LOCAL_LLM_MODEL=${LOCAL_LLM_MODEL:-llama3.2:latest}
      
      # ----- Anthropic (Claude) -----
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      # Für 'claude setup-token': Token hier einfügen
      - ANTHROPIC_SETUP_TOKEN=${ANTHROPIC_SETUP_TOKEN:-}
      
      # ----- Groq (Optional, Fallback) -----
      - GROQ_API_KEY=${GROQ_API_KEY:-}
      
      # ----- OpenAI (Optional) -----
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      
      # ----- Routing -----
      # "local" = Routing via lokales LLM, "groq" = Routing via Groq
      - ROUTER_PROVIDER=${ROUTER_PROVIDER:-local}
      
      # ----- Budget Limits (USD) -----
      - DAILY_BUDGET_SOFT=${DAILY_BUDGET_SOFT:-5.0}
      - DAILY_BUDGET_MEDIUM=${DAILY_BUDGET_MEDIUM:-15.0}
      - DAILY_BUDGET_HARD=${DAILY_BUDGET_HARD:-50.0}
      
      # ----- Rate Limits -----
      - RATE_LIMIT_RPM=${RATE_LIMIT_RPM:-60}
      - RATE_LIMIT_TPM=${RATE_LIMIT_TPM:-100000}
      
      # ----- Cache -----
      - CACHE_DIR=/app/data
      - SEMANTIC_THRESHOLD=${SEMANTIC_THRESHOLD:-0.92}
      
      # ----- Context Budgets (Tokens) -----
      - CONTEXT_BUDGET_CHEAP=${CONTEXT_BUDGET_CHEAP:-4000}
      - CONTEXT_BUDGET_PREMIUM=${CONTEXT_BUDGET_PREMIUM:-16000}
    
    volumes:
      # Persistente Daten (Cache, Budget-DB)
      - gateway-data:/app/data
      # Optionale Konfigurationsdatei
      - ./config/config.yaml:/app/config/config.yaml:ro
    
    extra_hosts:
      # Ermöglicht Zugriff auf Host-Services (Ollama)
      - "host.docker.internal:host-gateway"
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
    
    deploy:
      resources:
        limits:
          cpus: "2"
          memory: 2G
        reservations:
          cpus: "0.5"
          memory: 512M
    
    networks:
      - gateway-network
    
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ==========================================
  # Dashboard (React Frontend)
  # ==========================================
  dashboard:
    build:
      context: ./dashboard
      dockerfile: Dockerfile
    container_name: llm-gateway-dashboard
    restart: unless-stopped
    ports:
      - "${DASHBOARD_PORT:-3000}:80"
    depends_on:
      - gateway
    networks:
      - gateway-network
    profiles:
      - dashboard

  # ==========================================
  # Nginx Reverse Proxy (Optional)
  # ==========================================
  nginx:
    image: nginx:alpine
    container_name: llm-gateway-nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./config/nginx.conf:/etc/nginx/conf.d/default.conf:ro
    depends_on:
      - gateway
    networks:
      - gateway-network
    profiles:
      - with-nginx

  # ==========================================
  # Prometheus (Metriken)
  # ==========================================
  prometheus:
    image: prom/prometheus:latest
    container_name: llm-gateway-prometheus
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./config/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
    networks:
      - gateway-network
    profiles:
      - monitoring

  # ==========================================
  # Grafana (Dashboards)
  # ==========================================
  grafana:
    image: grafana/grafana:latest
    container_name: llm-gateway-grafana
    restart: unless-stopped
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana-data:/var/lib/grafana
    depends_on:
      - prometheus
    networks:
      - gateway-network
    profiles:
      - monitoring

volumes:
  gateway-data:
    driver: local
  prometheus-data:
    driver: local
  grafana-data:
    driver: local

networks:
  gateway-network:
    driver: bridge
