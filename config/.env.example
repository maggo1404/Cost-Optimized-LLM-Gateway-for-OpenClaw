# LLM Gateway v1.3 - Environment Configuration
# =============================================
# Copy to .env and fill in your values

# ===================
# API Keys (REQUIRED)
# ===================

# Groq API Key (for router + cheap tier)
# Get from: https://console.groq.com/keys
GROQ_API_KEY=gsk_...

# Anthropic API Key (for premium tier)
# Get from: https://console.anthropic.com/settings/keys
ANTHROPIC_API_KEY=sk-ant-...

# OpenAI API Key (optional, for embeddings fallback)
# Get from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-...

# ===================
# Gateway Security
# ===================

# Secret token for API authentication
# Generate with: openssl rand -hex 32
GATEWAY_SECRET=change-me-generate-random-secret

# ===================
# Budget Limits (USD)
# ===================

# Soft limit: Warning logged, full speed continues
DAILY_BUDGET_SOFT=5.0

# Medium limit: Premium tier throttled, cheap continues
DAILY_BUDGET_MEDIUM=15.0

# Hard limit: All requests blocked until midnight
DAILY_BUDGET_HARD=50.0

# ===================
# Rate Limits
# ===================

# Requests per minute (global)
RATE_LIMIT_RPM=60

# Tokens per minute (global)
RATE_LIMIT_TPM=100000

# ===================
# Cache Settings
# ===================

# Directory for cache databases
CACHE_DIR=/opt/llm-gateway/data

# Semantic similarity threshold (0.0-1.0)
# Higher = stricter matching, fewer cache hits
SEMANTIC_THRESHOLD=0.92

# ===================
# Context Budgets
# ===================

# Max tokens for cheap tier (Haiku/Llama)
CONTEXT_BUDGET_CHEAP=4000

# Max tokens for premium tier (Sonnet)
CONTEXT_BUDGET_PREMIUM=16000

# ===================
# Server Settings
# ===================

# Host and port
HOST=0.0.0.0
PORT=8000

# Environment (development, production)
ENV=production

# ===================
# Logging
# ===================

# Log level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Log format (json, text)
LOG_FORMAT=json

# Log file (optional)
# LOG_FILE=/var/log/llm-gateway/gateway.log
